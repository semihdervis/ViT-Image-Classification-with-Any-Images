{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f17b1157ad49ceba0bb3e74c8601a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/3662 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semih\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\semih\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e095d400ccd457fa75ada14d97df848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semih\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\vit\\modeling_vit.py:252: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1698, 'grad_norm': 1.4556313753128052, 'learning_rate': 0.00019731182795698925, 'epoch': 0.05}\n",
      "{'loss': 0.852, 'grad_norm': 1.0453912019729614, 'learning_rate': 0.0001946236559139785, 'epoch': 0.11}\n",
      "{'loss': 0.8861, 'grad_norm': 0.5025181770324707, 'learning_rate': 0.00019193548387096775, 'epoch': 0.16}\n",
      "{'loss': 0.7948, 'grad_norm': 10.801403045654297, 'learning_rate': 0.000189247311827957, 'epoch': 0.22}\n",
      "{'loss': 0.6557, 'grad_norm': 2.3779098987579346, 'learning_rate': 0.00018655913978494625, 'epoch': 0.27}\n",
      "{'loss': 0.8153, 'grad_norm': 2.8715460300445557, 'learning_rate': 0.00018387096774193548, 'epoch': 0.32}\n",
      "{'loss': 0.8188, 'grad_norm': 0.9872220158576965, 'learning_rate': 0.00018118279569892475, 'epoch': 0.38}\n",
      "{'loss': 0.5689, 'grad_norm': 1.0359077453613281, 'learning_rate': 0.00017849462365591398, 'epoch': 0.43}\n",
      "{'loss': 0.7094, 'grad_norm': 1.143519639968872, 'learning_rate': 0.00017580645161290325, 'epoch': 0.48}\n",
      "{'loss': 0.8534, 'grad_norm': 1.0831692218780518, 'learning_rate': 0.00017311827956989248, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e79efb089b446d89b359e054f5e77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7068464756011963, 'eval_accuracy': 0.7515151515151515, 'eval_runtime': 2.0267, 'eval_samples_per_second': 162.823, 'eval_steps_per_second': 20.723, 'epoch': 0.54}\n",
      "{'loss': 0.7839, 'grad_norm': 2.110886573791504, 'learning_rate': 0.00017043010752688172, 'epoch': 0.59}\n",
      "{'loss': 0.6712, 'grad_norm': 1.1638151407241821, 'learning_rate': 0.00016774193548387098, 'epoch': 0.65}\n",
      "{'loss': 0.7448, 'grad_norm': 0.6875391602516174, 'learning_rate': 0.00016505376344086022, 'epoch': 0.7}\n",
      "{'loss': 0.7018, 'grad_norm': 1.2545368671417236, 'learning_rate': 0.00016236559139784946, 'epoch': 0.75}\n",
      "{'loss': 0.7516, 'grad_norm': 0.8829709887504578, 'learning_rate': 0.00015967741935483872, 'epoch': 0.81}\n",
      "{'loss': 0.7675, 'grad_norm': 1.0640416145324707, 'learning_rate': 0.00015698924731182796, 'epoch': 0.86}\n",
      "{'loss': 0.698, 'grad_norm': 0.7242034077644348, 'learning_rate': 0.00015430107526881722, 'epoch': 0.91}\n",
      "{'loss': 0.9138, 'grad_norm': 1.1022175550460815, 'learning_rate': 0.00015161290322580646, 'epoch': 0.97}\n",
      "{'loss': 0.7772, 'grad_norm': 1.1229387521743774, 'learning_rate': 0.00014892473118279572, 'epoch': 1.02}\n",
      "{'loss': 0.5407, 'grad_norm': 5.182249069213867, 'learning_rate': 0.00014623655913978496, 'epoch': 1.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beb19ef3ed6469997c8c231651fee59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6504932045936584, 'eval_accuracy': 0.7484848484848485, 'eval_runtime': 1.8829, 'eval_samples_per_second': 175.262, 'eval_steps_per_second': 22.306, 'epoch': 1.08}\n",
      "{'loss': 0.8373, 'grad_norm': 0.7066428661346436, 'learning_rate': 0.00014354838709677422, 'epoch': 1.13}\n",
      "{'loss': 0.583, 'grad_norm': 1.286678433418274, 'learning_rate': 0.00014086021505376346, 'epoch': 1.18}\n",
      "{'loss': 0.4949, 'grad_norm': 1.0037462711334229, 'learning_rate': 0.0001381720430107527, 'epoch': 1.24}\n",
      "{'loss': 0.5139, 'grad_norm': 0.7832070589065552, 'learning_rate': 0.00013548387096774193, 'epoch': 1.29}\n",
      "{'loss': 0.6129, 'grad_norm': 1.1215609312057495, 'learning_rate': 0.0001327956989247312, 'epoch': 1.34}\n",
      "{'loss': 0.597, 'grad_norm': 0.653411328792572, 'learning_rate': 0.00013010752688172043, 'epoch': 1.4}\n",
      "{'loss': 0.7375, 'grad_norm': 1.1260840892791748, 'learning_rate': 0.0001274193548387097, 'epoch': 1.45}\n",
      "{'loss': 0.671, 'grad_norm': 1.0885182619094849, 'learning_rate': 0.00012473118279569893, 'epoch': 1.51}\n",
      "{'loss': 0.514, 'grad_norm': 1.1134769916534424, 'learning_rate': 0.00012204301075268818, 'epoch': 1.56}\n",
      "{'loss': 0.478, 'grad_norm': 0.5615193247795105, 'learning_rate': 0.00011935483870967743, 'epoch': 1.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16668afd73f473db1c22112b9bd6d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6633191704750061, 'eval_accuracy': 0.7636363636363637, 'eval_runtime': 1.8628, 'eval_samples_per_second': 177.151, 'eval_steps_per_second': 22.547, 'epoch': 1.61}\n",
      "{'loss': 0.6966, 'grad_norm': 1.2594823837280273, 'learning_rate': 0.00011666666666666668, 'epoch': 1.67}\n",
      "{'loss': 0.6268, 'grad_norm': 1.7371882200241089, 'learning_rate': 0.00011397849462365593, 'epoch': 1.72}\n",
      "{'loss': 0.6121, 'grad_norm': 1.5216954946517944, 'learning_rate': 0.00011129032258064515, 'epoch': 1.77}\n",
      "{'loss': 0.5024, 'grad_norm': 1.3477145433425903, 'learning_rate': 0.0001086021505376344, 'epoch': 1.83}\n",
      "{'loss': 0.672, 'grad_norm': 1.0715265274047852, 'learning_rate': 0.00010591397849462365, 'epoch': 1.88}\n",
      "{'loss': 0.6296, 'grad_norm': 3.713111400604248, 'learning_rate': 0.0001032258064516129, 'epoch': 1.94}\n",
      "{'loss': 0.6717, 'grad_norm': 1.4756056070327759, 'learning_rate': 0.00010053763440860215, 'epoch': 1.99}\n",
      "{'loss': 0.5909, 'grad_norm': 3.632136821746826, 'learning_rate': 9.78494623655914e-05, 'epoch': 2.04}\n",
      "{'loss': 0.5235, 'grad_norm': 1.5373965501785278, 'learning_rate': 9.516129032258065e-05, 'epoch': 2.1}\n",
      "{'loss': 0.4673, 'grad_norm': 1.8221487998962402, 'learning_rate': 9.247311827956989e-05, 'epoch': 2.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74853b2d9b6d4830aa354f0f7143a29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5752906799316406, 'eval_accuracy': 0.793939393939394, 'eval_runtime': 1.9159, 'eval_samples_per_second': 172.247, 'eval_steps_per_second': 21.922, 'epoch': 2.15}\n",
      "{'loss': 0.4867, 'grad_norm': 3.231328248977661, 'learning_rate': 8.978494623655914e-05, 'epoch': 2.2}\n",
      "{'loss': 0.4909, 'grad_norm': 0.8531060814857483, 'learning_rate': 8.709677419354839e-05, 'epoch': 2.26}\n",
      "{'loss': 0.389, 'grad_norm': 1.2248698472976685, 'learning_rate': 8.440860215053764e-05, 'epoch': 2.31}\n",
      "{'loss': 0.4955, 'grad_norm': 3.5868959426879883, 'learning_rate': 8.172043010752689e-05, 'epoch': 2.37}\n",
      "{'loss': 0.5262, 'grad_norm': 2.8980119228363037, 'learning_rate': 7.903225806451613e-05, 'epoch': 2.42}\n",
      "{'loss': 0.5601, 'grad_norm': 1.0979009866714478, 'learning_rate': 7.634408602150538e-05, 'epoch': 2.47}\n",
      "{'loss': 0.3772, 'grad_norm': 1.8252800703048706, 'learning_rate': 7.365591397849463e-05, 'epoch': 2.53}\n",
      "{'loss': 0.5798, 'grad_norm': 1.623577356338501, 'learning_rate': 7.096774193548388e-05, 'epoch': 2.58}\n",
      "{'loss': 0.5264, 'grad_norm': 0.49182307720184326, 'learning_rate': 6.827956989247311e-05, 'epoch': 2.63}\n",
      "{'loss': 0.3762, 'grad_norm': 2.0443458557128906, 'learning_rate': 6.559139784946236e-05, 'epoch': 2.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b3f348cf0e4d22adc59c80d99d9604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5808688998222351, 'eval_accuracy': 0.806060606060606, 'eval_runtime': 1.8913, 'eval_samples_per_second': 174.485, 'eval_steps_per_second': 22.207, 'epoch': 2.69}\n",
      "{'loss': 0.4606, 'grad_norm': 1.7373626232147217, 'learning_rate': 6.290322580645161e-05, 'epoch': 2.74}\n",
      "{'loss': 0.4491, 'grad_norm': 2.6274023056030273, 'learning_rate': 6.021505376344086e-05, 'epoch': 2.8}\n",
      "{'loss': 0.5265, 'grad_norm': 2.8111517429351807, 'learning_rate': 5.752688172043011e-05, 'epoch': 2.85}\n",
      "{'loss': 0.4482, 'grad_norm': 2.3688714504241943, 'learning_rate': 5.4838709677419355e-05, 'epoch': 2.9}\n",
      "{'loss': 0.4656, 'grad_norm': 1.8154428005218506, 'learning_rate': 5.2150537634408605e-05, 'epoch': 2.96}\n",
      "{'loss': 0.3828, 'grad_norm': 1.449847936630249, 'learning_rate': 4.9462365591397855e-05, 'epoch': 3.01}\n",
      "{'loss': 0.3487, 'grad_norm': 0.42441222071647644, 'learning_rate': 4.67741935483871e-05, 'epoch': 3.06}\n",
      "{'loss': 0.3545, 'grad_norm': 1.6662935018539429, 'learning_rate': 4.408602150537635e-05, 'epoch': 3.12}\n",
      "{'loss': 0.2477, 'grad_norm': 1.9020490646362305, 'learning_rate': 4.13978494623656e-05, 'epoch': 3.17}\n",
      "{'loss': 0.268, 'grad_norm': 1.3891819715499878, 'learning_rate': 3.870967741935484e-05, 'epoch': 3.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c73ce181704da89b6eaec345538ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5549391508102417, 'eval_accuracy': 0.796969696969697, 'eval_runtime': 2.0841, 'eval_samples_per_second': 158.339, 'eval_steps_per_second': 20.152, 'epoch': 3.23}\n",
      "{'loss': 0.3444, 'grad_norm': 6.237390995025635, 'learning_rate': 3.602150537634409e-05, 'epoch': 3.28}\n",
      "{'loss': 0.3708, 'grad_norm': 5.466879367828369, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n",
      "{'loss': 0.2087, 'grad_norm': 0.4771074950695038, 'learning_rate': 3.0645161290322585e-05, 'epoch': 3.39}\n",
      "{'loss': 0.3231, 'grad_norm': 1.6142545938491821, 'learning_rate': 2.7956989247311828e-05, 'epoch': 3.44}\n",
      "{'loss': 0.3607, 'grad_norm': 2.0825023651123047, 'learning_rate': 2.5268817204301075e-05, 'epoch': 3.49}\n",
      "{'loss': 0.2245, 'grad_norm': 2.978687286376953, 'learning_rate': 2.258064516129032e-05, 'epoch': 3.55}\n",
      "{'loss': 0.3053, 'grad_norm': 1.6812710762023926, 'learning_rate': 1.989247311827957e-05, 'epoch': 3.6}\n",
      "{'loss': 0.2696, 'grad_norm': 3.742980480194092, 'learning_rate': 1.7204301075268818e-05, 'epoch': 3.66}\n",
      "{'loss': 0.291, 'grad_norm': 1.6773072481155396, 'learning_rate': 1.4516129032258066e-05, 'epoch': 3.71}\n",
      "{'loss': 0.2762, 'grad_norm': 0.17142069339752197, 'learning_rate': 1.1827956989247313e-05, 'epoch': 3.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde6bc13ce0c4692a9b098b5f212aafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5628989338874817, 'eval_accuracy': 0.7818181818181819, 'eval_runtime': 1.9213, 'eval_samples_per_second': 171.759, 'eval_steps_per_second': 21.86, 'epoch': 3.76}\n",
      "{'loss': 0.3178, 'grad_norm': 0.31403791904449463, 'learning_rate': 9.13978494623656e-06, 'epoch': 3.82}\n",
      "{'loss': 0.2307, 'grad_norm': 2.097884178161621, 'learning_rate': 6.451612903225806e-06, 'epoch': 3.87}\n",
      "{'loss': 0.3203, 'grad_norm': 3.1524269580841064, 'learning_rate': 3.763440860215054e-06, 'epoch': 3.92}\n",
      "{'loss': 0.3157, 'grad_norm': 1.4197919368743896, 'learning_rate': 1.0752688172043011e-06, 'epoch': 3.98}\n",
      "{'train_runtime': 164.9859, 'train_samples_per_second': 71.885, 'train_steps_per_second': 4.509, 'train_loss': 0.5454547696857042, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf98a6f03f049b095b08c30ed8ac80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict, load_metric\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load and preprocess dataset\n",
    "ds = load_dataset('betul2').rename_column('label', 'labels')\n",
    "ds = ds['train'].train_test_split(test_size=0.1)\n",
    "train_val = ds['train'].train_test_split(test_size=0.1)\n",
    "ds['train'], ds['validation'], ds['test'] = train_val['train'], train_val['test'], ds['test']\n",
    "dataset = DatasetDict(ds)\n",
    "\n",
    "# Initialize feature extractor and model\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "labels = ds['train'].features['labels'].names\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ").to(device)\n",
    "\n",
    "# Transform function\n",
    "def transform(example_batch):\n",
    "    images = [np.moveaxis(np.array(x.convert('RGB')), -1, 0) for x in example_batch['image']]\n",
    "    inputs = feature_extractor(images, return_tensors='pt')\n",
    "    inputs['labels'] = example_batch['labels']\n",
    "    return inputs\n",
    "\n",
    "# Prepare dataset\n",
    "prepared_ds = ds.with_transform(transform)\n",
    "\n",
    "# Data collator\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "# Metric and compute function\n",
    "metric = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit-base--v5\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=4,\n",
    "    fp16=True,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Trainer initialization\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"validation\"],\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "# Model card creation\n",
    "kwargs = {\n",
    "    \"finetuned_from\": model.config._name_or_path,\n",
    "    \"tasks\": \"image-classification\",\n",
    "    \"dataset\": 'custom brats layers',\n",
    "    \"tags\": ['image-classification'],\n",
    "}\n",
    "if training_args.push_to_hub:\n",
    "    trainer.push_to_hub('ðŸ» cheers', **kwargs)\n",
    "else:\n",
    "    trainer.create_model_card(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae84e5e058794854938207dfc632c736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4978531301021576,\n",
       " 'eval_accuracy': 0.8256130790190735,\n",
       " 'eval_runtime': 2.3023,\n",
       " 'eval_samples_per_second': 159.403,\n",
       " 'eval_steps_per_second': 19.98,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(prepared_ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4978531301021576, 'eval_accuracy': 0.8256130790190735, 'eval_runtime': 2.2373, 'eval_samples_per_second': 164.039, 'eval_steps_per_second': 20.561, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
